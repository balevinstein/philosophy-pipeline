# Philosophy Pipeline Setup Guide

This guide helps new collaborators set up the Philosophy Pipeline development environment.

## ğŸš€ Quick Setup

### 1. **Clone and Install Dependencies**
```bash
git clone [repository]
cd philosophy-pipeline
pip install -r requirements.txt
```

### 2. **Set Up Analysis Papers Directory**

The pipeline needs Analysis journal papers for style guidance and pattern extraction. Many Analysis papers are open access.

```bash
# Create the Analysis papers directory
mkdir -p Analysis_papers

# Download open access Analysis papers (examples)
# You can find these at: https://academic.oup.com/analysis
# Look for papers marked as "Open Access" or use institutional access
```

**Recommended papers to download:**
- Recent Analysis papers from 2020-2024 (any 10-20 papers will do)
- Save as PDF files with descriptive names
- Papers used in current development: `anab031.pdf`, `anab033.pdf`, `anab039.pdf`, `anae045.pdf`

### 3. **Extract Text from PDFs (Optional)**
If you've added new Analysis papers, extract text for better token efficiency:

```bash
# Run the extraction script
python scripts/extract_analysis_cache.py
```

This will:
- Extract TXT versions of PDFs from `Analysis_papers/`
- Save text extracts to `data/analysis_extracts/`
- Create paper index in `analysis_cache/paper_index.json`

**Note**: Text extracts are ~3x more token-efficient than processing PDFs directly.

## ğŸ“ **Expected Directory Structure After Setup**

```
philosophy-pipeline/
â”œâ”€â”€ Analysis_papers/          # Your downloaded PDFs (gitignored)
â”‚   â”œâ”€â”€ anab031.pdf
â”‚   â”œâ”€â”€ anab033.pdf
â”‚   â””â”€â”€ [... other Analysis papers]
â”œâ”€â”€ data/                     # Curated data (already in repo)
â”‚   â”œâ”€â”€ philosophical_moves/
â”‚   â”œâ”€â”€ analysis_extracts/
â”‚   â””â”€â”€ style_guides/
â”œâ”€â”€ analysis_cache/           # Generated after extraction (gitignored)
â”‚   â”œâ”€â”€ extracted_texts/
â”‚   â””â”€â”€ paper_index.json
â””â”€â”€ [... rest of pipeline]
```

## ğŸ§ª **Testing Your Setup**

### Test Individual Phases:
```bash
# Test Phase I.1 (topic generation)
python run_phase_1_1.py

# Test Phase II.1 (requires Analysis papers)
python run_phase_2_1.py
```

### Test Complete Pipeline:
```bash
# Full pipeline run (takes ~2 hours)
python run_pipeline.py
```

## ğŸ”§ **Development Workflow**

### **Adding New Analysis Papers:**
1. Download PDF to `Analysis_papers/`
2. Run `python scripts/extract_analysis_cache.py`
3. New extracts appear in `analysis_cache/extracted_texts/`

### **Testing Individual Components:**
- See `docs/development/testing_guide.md` for detailed testing procedures
- Each phase can be run independently for development

### **Modifying Philosophical Moves:**
- Edit `data/philosophical_moves/injectable_examples.json`
- Changes take effect immediately in Phase II.7

## ğŸš¨ **Common Issues**

### **"Analysis_papers directory not found"**
- Create the directory: `mkdir Analysis_papers`
- Add at least a few Analysis journal PDFs

### **"No PDF files found"**
- Download PDF files from Analysis journal
- Ensure files have `.pdf` extension
- Check file permissions

### **"ModuleNotFoundError"**
- Install dependencies: `pip install -r requirements.txt`
- Check Python version (3.8+ recommended)

### **"Token limit exceeded"**
- Use TXT extracts instead of PDFs: run `scripts/extract_analysis_cache.py`
- TXT files are automatically used when available

## ğŸ“Š **Resource Requirements**

**Minimum Setup:**
- Python 3.8+
- 2GB free disk space
- OpenAI API key (set in `.env`)
- 5-10 Analysis journal PDFs

**Recommended Setup:**
- 20+ Analysis journal PDFs
- Text extracts generated
- Claude API access (for PDF processing)

## ğŸ¤ **Collaboration Notes**

**What's in the repo:**
- âœ… All pipeline code
- âœ… Curated philosophical moves database
- âœ… TXT extracts from Analysis papers
- âœ… Style guides and examples

**What you need to add:**
- âŒ Analysis journal PDFs (not in repo due to size/copyright)
- âŒ Your `.env` file with API keys
- âŒ Generated outputs (in `outputs/`, gitignored)

**Best practices:**
- Use TXT extracts when possible (more efficient)
- Test individual phases before full pipeline runs
- Add new philosophical moves to the curated database
- Follow the documentation structure for new features 